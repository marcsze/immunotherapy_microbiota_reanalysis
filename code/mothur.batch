#!bash

#Load needed R
module load R/3.3.0
module load sratoolkit/2.8.2-1

# module list

#module load sratoolkit/2.7.0
mothurRv=/nfs/turbo/schloss-lab/bin/mothur
DOWNDIR=data/raw
WORKDIR=data/process
REF=data/references




# Download the data set
#wget -r -q -np -nd -P $DOWNDIR ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP098/SRP098484/
	# easier to use the SRAtoolkit built in fetch function than parse the html/xml 
	# for the download

prefetch -O $DOWNDIR --option-file $WORKDIR/metadata/SraAccList.txt
	# creation of the .txt file can be done by searching the desired SRP
	# e.g. SRP098484 and following the instructions at
		# https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/
	# namely 
		# Run accessions are used to download SRA data.
		# To download a list of Run accessions selected from your Entrez search:

			#Click 'Send to' on the top of the page, 
			#check the radiobutton 'File', 
			# select 'Accession List'.
		
		#Save this file in the location from which you are running the SRA Toolkit.


# Convert to fasta files that will be used
for sample in $DOWNDIR/*.sra
do
	fastq-dump --split-files $sample -O $WORKDIR

	rm $sample

	echo "Completed ${sample} processing." 

done


# # Run mothur for sequencing processing on combined file
$mothurRv "#make.file(inputdir=$WORKDIR, type=fastq, prefix=stability)"

# Change sequences names for mothur processing

Rscript code/make_nice_mothur_file.R


# Run mothur for sequencing processing on combined file
$mothurRv "#make.contigs(file=$WORKDIR/stability.files, inputdir=$WORKDIR);
	summary.seqs(fasta=current, processors=8);
	screen.seqs(fasta=current, group=current, maxambig=0, maxlength=275);
	summary.seqs(fasta=current);
	unique.seqs(fasta=current);
	count.seqs(name=current, group=current);
	align.seqs(fasta=current, reference=$REF/silva.seed.align);
	summary.seqs(fasta=current, count=current)"
# 	screen.seqs(fasta=current, count=current, start=13862, end=23444, maxhomop=8);
# 	filter.seqs(fasta=current, vertical=T, trump=.);
# 	unique.seqs(fasta=current, count=current);
# 	summary.seqs(fasta=current, count=current);
# 	pre.cluster(fasta=current, count=current, diffs=2);
# 	chimera.vsearch(fasta=current, count=current, dereplicate=t);
# 	remove.seqs(fasta=current, accnos=current);
# 	classify.seqs(fasta=current, count=current, reference=$REF/trainset14_032015.pds.fasta, taxonomy=$REF/trainset14_032015.pds.tax, cutoff=80);
# 	remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota);
# 	remove.groups(fasta=current, count=current, taxonomy=current, groups=mock1-mock2-mock5-mock6-mock7);
# 	cluster.split(fasta=current, count=current, taxonomy=current, method=opti, metric=mcc, taxlevel=5, cutoff=0.03, processors=8);
# 	make.shared(list=current, count=current, label=0.03);
# 	classify.otu(list=current, count=current, taxonomy=current, label=0.03);
# 	get.oturep(fasta=current, count=current, list=current, label=0.03, method=abundance);
# 	count.groups()"


